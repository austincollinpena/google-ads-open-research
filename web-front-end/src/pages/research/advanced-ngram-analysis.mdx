---
layout: ../../layouts/blog-explicit-prose.astro
title: Kill Wasted Spend And Scale What Works With Layered N-Gram Analysis
headline: Kill Wasted Spend And Scale What Works With Layered N-Gram Analysis
description: Layered n gram analysis is the most effective way to improve search term performance.
image: "/generated/computer-with-eyes.png"
publishDate: "September 6 2022"
draft: false
---

import Image from "../../components/Image.astro";

import Ngram from "../../components/tool/NGramUploader.tsx";

<div class="prose prose-xl mx-4 md:mx-auto my-12">

# Advanced N-Gram Analysis For Google Ads With Python

</div>

<div class="prose prose-xl mx-4 md:mx-auto my-12">

---

**Summary**

1. Analyze your search term performance and find what should scale and what you should cut
2. Add a CPA/ROAS target to clearly see what grams are over or under your goals
3. Access and reuse the code anyway you like. [View the source code here.](https://github.com/austincollinpena/google-ads-open-research/blob/main/python_code/n_gram/vector_n_gram_for_cloud_functions.py)

_Big thank you to [Dan Willoughby](https://www.linkedin.com/in/dan-willoughby-092539196/) and the team at [Adevolver](https://adevolver.com/) for the help with this._

---

[Skip the explanation and jump to the tool](#n-gram-tool) ◀◀◀

## How n-grams help you become more profitable

### But first, what are they?

If you've managed Google Ads Accounts for a while, you've likely intuitively used them. For example, you might have a phrase match of "how to" or "diy" negatives for your accounts.

You know that these terms are very unlikely to bring in quality searches.

N grams are a way to use your data to find how common phrases do across a large amount of search terms.

If you put a 1000 search terms and find the common phrases, or "n-grams", you can quickly make judgements on the efficacy of those n-grams.

The common phrase or 2 gram of "near me" for a local account is likely very positive.

The common phrase or 3 gram of "how do I" for a local account is very negative.

Using n grams helps you get data out of your search terms _faster_.

### Quick example

Let's say you're a D2C deodarant company. You've got about 1,000 ways that people search for deodarant.

Most of those long tail search terms don't have enough data to say if they're "good" or "bad"

For example, "best deodarant for men mint smell no aluminum" might only have 3 clicks. Is the term worth continuing to bid on or not?

This is where n grams come in.

An n gram analysis might now that the 4 gram of "best deodarant for men" is highly profitable. Therefore, it is likely that this search term will become profitable.

### Where traditional n gram analysis fails

In a traditional analysis, n grams are all aggregated together and produce a score.

The 4 gram of "best deodarant for men" may have spent $10,000 and generated $15,000 in profit.

However, in most PPC accounts, it is likely that $8,000 of that spend resulted in $14,500 in that profit.

If you are able to find and cut the $2,000 in spend that lost your $1500, you can achieve more profit.

#### But wait, it gets worse

Let's say you have a 3 gram of "dove men deodarant" that spent $5,000 and only brought in $1,500 in revenue. Any PPC manager would be tempted to do a phrase match exclusion.

However, what if you could find out that all $1500 of that revenue came from search terms with $200 in spend?

For example, your exclusion of "dove men deodarant" could have negatived out "dove men deodarant alternatives" which is a great term.

In a traditional N Gram analysis, you would be open to making this mimstake. With layered n gram analysis, you will not.

## How layered N Gram analysis brings you effeciency

Layered n gram analysis allows you to set a CPA target or ROAS goal.

Each gram analysis is given two scores:

1. Regular
2. Efficient

The regular score factors in every single search term. The efficient score only factors in search terms that reach your ROAS or CPA goal.

If you have 1000 search terms and 200 of them beat your ROAS/CPA goal, you will get:

1. Each gram measured across all 1000 search terms
2. A second column, postfixed with \_efficient that only looks at the 200 that reached your goal

For example, the gram "deodarant for men" will have the two different scores. The first generated from all of the matching terms. The second generated from all terms beating the CPA/ROAS target.

<Image
  alt="sample n gram analysis"
  src="/sample-layered-n-gram.png"
  AspectRatio="2558:1148"
/>

By looking at the above, you can learn:

1. The gram "deodarant for men" spent $14,450 across all of your search terms
2. $68,812 of your revenue came from $11,400 of your spend
3. **$3050 of your spend on this gram is likely wasteful.** Only $11,400 is above your theshold and you'll lose very little revenue by finding and removing those terms

In a proper report, like below, you'll get a report showing multiple dimensions for each gram.

<Image
  alt="sample n gram analysis"
  src="/sample-gram-usage.png"
  AspectRatio="2558:1148"
/>

## The Free Tool

This tool is free to use. Upload a CSV here to get an analysis emailed to you.

_Important privacy notes:_

1. Your email is not used for any other reason than to send your results
2. Your data is not accessed or used for any other reason than sending your results
3. All data is deleted within 24 hours, whether or not you access it
4. If you want your data team to run this analysis for you, [here is the code](https://github.com/austincollinpena/google-ads-open-research/blob/main/python_code/n_gram/vector_n_gram_for_cloud_functions.py)

---

<div id="n-gram-tool" />

Export these columns from your search term report for this to work. You will be able to keep the default names that Google exports.

- Campaign
- Ad Group
- Search term
- Clicks
- Impressions
- Cost
- Conversions
- Conversion Value (If you have it, if not, select "CPA Target" below)
- Impressions (Top %)
- Impressions (Abs Top %)

**Important**: After you export, delete the first two rows of your export as well as the summary rows at the bottom.

</div>

<Ngram client:idle />

<div class="prose prose-xl mx-4 md:mx-auto my-12">

## FAQ about Layered N Gram analysis

### What should I do next?

Take this data and find the high performers and low performers in your account.

Consider giving your high performers special treatment, and segmenting (or adding negatives for) your low performers.

### What should I look out for?

It can be tempting to exclude phrases **too early** because of data from n gram analysis.

If you're dealing with low volume of data, it's better to "quarantine" your searches into specific campaigns with lower bids rather than excluding them outright.

### Why is this free to use?

Enough people hire me to automate big accounts or increase account efficiency making this worth it. [Send me an email at me@austinpena.com](mailto:me@austinpena.com) if that's something you're looking for.

</div>
